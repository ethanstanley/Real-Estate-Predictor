{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import ssl\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "import time\n",
    "import re\n",
    "import statistics\n",
    "import matplotlib.pyplot as py\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#To Do: get features and make data frame"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_links(pages = 1):\n",
    "    #gets the links from trulia properties page \n",
    "    # if length of list is zero, captcha blocked request so use a new VPN location \n",
    "    #pages: number of pages of trula to scrape\n",
    "    #returns: list of links\n",
    "    ctx = ssl.create_default_context()\n",
    "    ctx.check_hostname = False\n",
    "    ctx.verify_mode = ssl.CERT_NONE\n",
    "    i = 0\n",
    "    property_links = []\n",
    "    while i < pages:\n",
    "        url = 'https://www.trulia.com/NY/New_York/' + \"%s_p/\"%str(i)\n",
    "        req = Request(url, headers={\"User-Agent\": 'Mozilla/5.0'})\n",
    "        webpage = urlopen(req).read()\n",
    "        soup = BeautifulSoup(webpage , 'html.parser')\n",
    "        for link in soup.findAll('a'):\n",
    "            l = str(link.get('href'))\n",
    "            if sum(map(str.isdigit, l[-17:])) == 15: property_links.append(\"https://www.trulia.com\" + l)\n",
    "        property_links = property_links[::2]\n",
    "        print(\"finishing loop\" + \" \" + str(i+1))\n",
    "        i += 1\n",
    "        time.sleep(5)\n",
    "        \n",
    "    return(property_links)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "feature_dict_list = {}\n",
    "all_features = []\n",
    "all_links = []\n",
    "for index,url in enumerate(get_links()): #iterates through all URLs from the get_links func\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()  \n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    html = soup.prettify('utf-8')\n",
    "    feature_dict = {}\n",
    "\n",
    "    for sou in soup.findAll('span', attrs={\"class\":\"Feature__FeatureListItem-sc-w1mxt5-0 gmLKqq\"}):\n",
    "        clean_data = str(sou).split(\"gmLKqq\\\">\")\n",
    "        clean_data = clean_data[1].split(\"</span>\")[0]\n",
    "        dict_info = clean_data.split(':')\n",
    "        if len(dict_info)>1:\n",
    "            feature_dict[dict_info[0]] = dict_info[1]\n",
    "\n",
    "\n",
    "    for bed_html in soup.findAll('span', attrs={'data-testid':\"home-summary-size-bedrooms\"}):\n",
    "        number_beds = re.findall(r\"[0-9]+\\s[bB]eds*\", str(bed_html))\n",
    "        if number_beds:\n",
    "            feature_dict[\"beds\"] = int(number_beds[0].split(\" \")[0])\n",
    "\n",
    "    for bath_html in soup.findAll('div', attrs={'data-testid':\"home-summary-size-bathrooms\"}):\n",
    "        number_baths = re.findall(r\"[0-9]+\\s[bB]aths*\", str(bath_html))\n",
    "        if number_baths:\n",
    "            feature_dict[\"baths\"] = int(number_baths[0].split(\" \")[0])\n",
    "\n",
    "    for floor_html in soup.findAll('div', attrs={'data-testid':\"home-summary-size-floorspace\"}):\n",
    "        floor_footage = re.findall(r\"[0-9]+,[0-9]+\\ssqft*\", str(floor_html))\n",
    "        property_info[\"floor_space\"] = {}\n",
    "        if floor_footage:\n",
    "            feature_dict[\"floor_space\"][\"value\"] = int(floor_footage[0].split(\" \")[0].replace(\",\", \"\"))\n",
    "\n",
    "    all_features.append(feature_dict);all_links.append(url)\n",
    "    df = pd.DataFrame.from_dict(all_features)\n",
    "    \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finishing loop 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'baths' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[43mbaths\u001b[49m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baths' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for house in all_features:\n",
    "    for f in house:\n",
    "        dict_key,dict_value = f.split(':')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# For ignoring SSL certificate errors  (reused code)\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "#url = input(\"Enter URL: \")\n",
    "url = 'https://www.trulia.com/p/ny/staten-island/365-victory-blvd-staten-island-ny-10301--2008726710'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Use Mozilla access agent\n",
    "\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Creating a BeautifulSoup object of the html page for easy extraction of data.\n",
    "\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "html = soup.prettify('utf-8')\n",
    "property_info = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# This code block will get you a one liner description of the listed property\n",
    "\n",
    "for meta in soup.findAll('meta', attrs={'name': 'description'}):\n",
    "    try:\n",
    "        property_info['description'] = meta['content']\n",
    "        break\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "property_info['description']"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'description'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m: \n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mproperty_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'description'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Store url \n",
    "\n",
    "property_info['link'] = url\n",
    "\n",
    "property_info['link']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://www.trulia.com/p/ny/new-york/309-e-houston-st-1a-new-york-ny-10002--2478352572'"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "#Get beds, baths, floorspace\n",
    "\n",
    "for bed_html in soup.findAll('div', attrs={'data-testid':\"home-summary-size-bedrooms\"}):\n",
    "    number_beds = re.findall(r\"[0-9]+\\s[bB]eds*\", str(bed_html))\n",
    "    if number_beds:\n",
    "        property_info[\"beds\"] = int(number_beds[0].split(\" \")[0])\n",
    "\n",
    "for bath_html in soup.findAll('div', attrs={'data-testid':\"home-summary-size-bathrooms\"}):\n",
    "    number_baths = re.findall(r\"[0-9]+\\s[bB]aths*\", str(bath_html))\n",
    "    if number_baths:\n",
    "        property_info[\"baths\"] = int(number_baths[0].split(\" \")[0])\n",
    "\n",
    "for floor_html in soup.findAll('div', attrs={'data-testid':\"home-summary-size-floorspace\"}):\n",
    "    floor_footage = re.findall(r\"[0-9]+,[0-9]+\\ssqft*\", str(floor_html))\n",
    "    property_info[\"floor_space\"] = {}\n",
    "    if floor_footage:\n",
    "        property_info[\"floor_space\"][\"value\"] = int(floor_footage[0].split(\" \")[0].replace(\",\", \"\"))\n",
    "        property_info[\"floor_space\"][\"unit\"] = floor_footage[0].split(\" \")[1]\n",
    "\n",
    "property_info\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'link': 'https://www.trulia.com/p/ny/new-york/309-e-houston-st-1a-new-york-ny-10002--2478352572'}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "#Extracts features for given house\n",
    "for index, sou in enumerate(soup.findAll('span', attrs={\"class\":\"Feature__FeatureListItem-sc-w1mxt5-0 gmLKqq\"})):\n",
    "    clean_data = str(sou).split(\"gmLKqq\\\">\")\n",
    "    clean_data = clean_data[1].split(\"</span>\")[0]\n",
    "clean_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Lot Area: 3001 sqft'"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.13 64-bit ('env_tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "978aba30ef2e336260338d4a3e61c9d4e24765bf9dea0639d3bd4087679dac9a"
   }
  },
  "interpreter": {
   "hash": "24e04ac6381ae14c7283d3039b3eae55e580ec44d8ad9834709c61b9be756f0a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}